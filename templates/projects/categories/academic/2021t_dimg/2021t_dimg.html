<p><i>Overview:</i></p>
<ol>
    <li><b>Project 1: Linear Spatial Filtering</b></li>
    <ul style="list-style-type: none;">
        <li>
            <img style="max-width: 1000px" src="/projects/2021t_dimg/p1_lena_prewittx.jpg" class="center" />
        </li>
        <br>
        <li>The primary application for linear spatial filtering in image processing is usually for applying different
            distributions of noise, detecting linear signal properties like edges or corners, or detecting 'objects' by
            performing filtering and using a difference metric to see how disparate the region within the image is to
            the kernel. In this project, multiple linear operators (Sobel, Roberts, Prewitt, etc.) along with kernels
            like box & Gaussian were were implemented and tested. Above, you see the original image with the Prewitt
            operator along the 'x' (horizontal) direction being applied. Respective to each RGB channel, hence the
            color. After processed, the end result is the leftmost image. Below, the same operator in the 'y' (vertical)
            direction is applied and the magnitude is calculated on the leftmost image. Below the magnitude along the
            RGB channels is shown, hence why it is black and white. This is the most common application for these edge
            detecting operators, as it can be seen how effectively an edge is found.</li>
        <br>
        <li>Implemented in MATLAB, all figures are my own.</li>
        <br>
        <li>
            <img style="max-width: 1000px" src="/projects/2021t_dimg/p1_lena_mag.jpg" class="center" />
        </li>
        <div class="card">
            <!-- <p class="center_desc">x gradient</p> -->
            <!-- <p class="center_desc">y gradient</p> -->
            <!-- <p class="center_desc">gradient magntiude - sqrt(x^2 + y^2)</p> -->
            <p class="center_desc">x gradient ===> y gradient ===> gradient magntiude</p>
        </div>
        <br>
        <li>I understand there are social implications / movements within the image processing community to stop using
            this Lena image, however this was one of the primary images used during this class. More can be read in the
            report below, see the <i>Literature</i> section.</li>
        <br>
        <li><i>PS: I also did a lot more during all these 3 projects with respect to image processing. Some art may be
                coming soon :~) — simple / bad examples of what I did w.r.t. LSF + animations are shown below:</i></li>
        <br>
        <li>
            <div class="card">
                <img style="max-width: 200px" src="/projects/2021t_dimg/p0_0.gif" class="center" />
                <img style="max-width: 200px" src="/projects/2021t_dimg/p0_1.gif" class="center" />
                <img style="max-width: 200px" src="/projects/2021t_dimg/p0_2.gif" class="center" />
                <img style="max-width: 200px" src="/projects/2021t_dimg/p0_3.gif" class="center" />
            </div>
        </li>
    </ul>

    <br>
    <li><b>Project 2: Laplacian Blending</b></li>
    <ul style="list-style-type: none;">
        <li>A Gaussian 'pyramid' is essentially an image downsizing technique, where a variable amount of blur (but
            constant with respect to each 'pyramid') is applied to an image before downsampled. This downsizes the image
            while maintaining the 'look' of the image. The term 'pyramid' is used as a visualization if each successive
            downsample was tiled ontop of one another, creating a rectangular pyramid of sorts. A Laplacian pyramid can
            be approximated using a difference of Gaussian's at two respective blur amounts. This Laplacian pyramid was
            original made as a form of lossy image compression, where the original image can be reconstructed with a
            couple low-data Laplacian's that held detail of the image, and one single Gaussian (the lowest size of the
            pyramid) which held the color composition of the image. It was discovered that images can be blended during
            this reconstruction process by generating the Gaussian / Laplacian pyramids of two images as well as a mask.
            During reconstruction, the mask and its inverse is simply multiplied by each respective picture and then
            expanded. This creates a rudimentary blending effect. There is still room for color and texture correction,
            and this is why the example images shown blend objects with similar colors and textures. More can be read in
            the report below, see the <i>Literature</i> section.</li>
        <br>
        <li>Implemented blending and GUI for creating mask in MATLAB, all figures are my own.</li>
        <br>
        <li>
            <div class="card">
                <img style="max-width: 200px" src="/projects/2021t_dimg/p2_cat.jpg" class="center" />
                <img style="max-width: 200px" src="/projects/2021t_dimg/p2_dogcat.png" class="center" />
                <img style="max-width: 200px" src="/projects/2021t_dimg/p2_catdog.png" class="center" />
                <img style="max-width: 200px" src="/projects/2021t_dimg/p2_dog.jpg" class="center" />
            </div>
            <img style="max-width: 1000px" src="/projects/2021t_dimg/p2_hand.png" class="center" />
        </li>
    </ul>

    <br>
    <li><b>Project 3: Optimized Blob Detection — a Precursor to SIFT Detector</b></li>
    <ul style="list-style-type: none;">
        <li>A scale-invariant feature transform (SIFT) detector tries to detect features of an image invariant to
            transformations such as scale, rotation, and translation. The idea behind the SIFT detector is to take an
            image of some environment at different angles, lighting, etc., and to be able to extract key points within
            the image that align with both images, despite having some amount of linear relative distortion. The first
            step in finding these SIFT interest points happens to align with the same task of 'blob detection'. A series
            of linear spatial filters are applied to an image to detect edges of varying sizes. If an edge happens to be
            relatively circular + compact, the result constructively creates a 'blob', where the local maxima/minima of
            these blobs is a SIFT interest point. The size of each blob is a function of the types of filters used, the
            size of the image, and more.</li>
        <br>
        <li>For this project, there was an optional speed test for extra credit. I did not really need the extra credit,
            but I had already optimized my script / algorithm to such an extent where I decided go all out and compete.
            More can be read in the 'Algorithm' section of the report, shown below. I placed first in the competition.
        </li>
        <li> More can be read in the report below, see the <i>Literature</i> section.</li>
        <br>
        <li>Implemented in MATLAB, all figures are my own.</li>
        <br>
        <div class="card">
            <img style="max-width: 300px" src="/projects/2021t_dimg/p3_0.png" class="center" />
            <img style="max-width: 300px" src="/projects/2021t_dimg/p3_1.png" class="center" />
            <img style="max-width: 300px" src="/projects/2021t_dimg/p3_2.png" class="center" />
            <img style="max-width: 300px" src="/projects/2021t_dimg/p3_3.png" class="center" />
        </div>
        <div class="card">
            <img style="max-width: 300px" src="/projects/2021t_dimg/p3_7.png" class="center" />
            <img style="max-width: 350px" src="/projects/2021t_dimg/p3_6.png" class="center" />
            <img style="max-width: 300px" src="/projects/2021t_dimg/p3_5.png" class="center" />
            <img style="max-width: 300px" src="/projects/2021t_dimg/p3_4.png" class="center" />
        </div>
    </ul>
</ol>


<hr>
<p><i>Personal Statement:</i></p>
<p>Fun class. I like pictures.</p>

<!-- <hr>
<p><i>My Contribution:</i></p>
<p></p> -->

<hr>
<p><i>Literature:</i></p>
<a href="/files/notes/academic/2021%20-%20ECE%20558/Voros_Arpad_ECE558_proj1.pdf">Voros_Arpad_ECE558_proj1.pdf</a><br>
<a href="/files/notes/academic/2021%20-%20ECE%20558/Voros_Arpad_ECE558_proj2.pdf">Voros_Arpad_ECE558_proj2.pdf</a><br>
<a href="/files/notes/academic/2021%20-%20ECE%20558/Voros_Arpad_ECE558_proj3.pdf">Voros_Arpad_ECE558_proj3.pdf</a><br><br>
<iframe class="center" src="/academic/2021%20-%20ECE%20558/Voros_Arpad_ECE558_proj3.pdf" width=60%
    height=950></iframe>

<hr>
<p><i>Media Citation(s):</i></p>
<p>Dog and Cat (not blended) - <a href="https://www.google.com/imghp?hl=en">https://www.google.com/imghp?hl=en</a></p>
<p>Test images prior to manipulation (Lena, Einstein, peppers, etc.) - <a
        href="http://www.imageprocessingplace.com/root_files_V3/image_databases.htm">http://www.imageprocessingplace.com/root_files_V3/image_databases.htm</a>
</p>